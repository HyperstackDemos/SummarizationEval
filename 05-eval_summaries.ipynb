{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate summaries\n",
    "\n",
    "Lets evaluate the quality of the resulting summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing an appropriate metric\n",
    "\n",
    "We will consider first, [ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)), which measures the number of overlapping textual units (n-grams) between the summary and the reference. \n",
    "\n",
    "Install it with the `install_rouge.sh` script, as it involves a few steps.\n",
    "\n",
    "Let's create some sample summaries to gain an intuition of this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted from https://en.wikipedia.org/wiki/Automatic_summarization\n",
    "reference_text = \"\"\"Automatic summarization is the process of shortening a set of data computationally,\n",
    "to create a subset (a summary) that represents the most important or relevant information within the original content.\n",
    "Artificial intelligence algorithms are commonly developed and employed to achieve this, specialized for different types of data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "summary_A = \"Automatic summarization consists of turning longer input data into a shorter subset, keeping the most important parts\"\n",
    "summary_B = \"Automatic summarization is the process of shortening data computationally into a subset of most relevant information\"\n",
    "summary_C = \"Automatic summarization computationally relevant Artificial intelligence specialized data\"\n",
    "\n",
    "summaries = [summary_A, summary_B, summary_C]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write the texts to file to calculate the ROUGE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./metrics/sample/system.001.txt\", \"w+\") as system:\n",
    "    system.write(reference_text)\n",
    "\n",
    "letters = [\"A\", \"B\", \"C\"]\n",
    "for index, summary in enumerate(summaries):\n",
    "    with open(f\"./metrics/sample/model.{letters[index]}.001.txt\", \"w+\") as model:\n",
    "        model.write(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrouge import Rouge155\n",
    "\n",
    "def get_rouge_l_f(model):\n",
    "    r = Rouge155()\n",
    "    r.system_dir = \"./metrics/sample/\"\n",
    "    r.model_dir = \"./metrics/sample/\"\n",
    "    r.system_filename_pattern = \"system.(\\d+).txt\"\n",
    "    r.model_filename_pattern = f\"model.{model}.#ID#.txt\"\n",
    "\n",
    "    output = r.convert_and_evaluate()\n",
    "    return r.output_to_dict(output)[\"rouge_l_f_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 14:03:06,320 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2024-04-11 14:03:06,324 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpzhg8lk99/system and model files to /tmp/tmpzhg8lk99/model.\n",
      "2024-04-11 14:03:06,325 [MainThread  ] [INFO ]  Processing files in ./metrics/sample/.\n",
      "2024-04-11 14:03:06,325 [MainThread  ] [INFO ]  Processing system.001.txt.\n",
      "2024-04-11 14:03:06,326 [MainThread  ] [INFO ]  Processing model.B.001.txt.\n",
      "2024-04-11 14:03:06,327 [MainThread  ] [INFO ]  Processing model.C.001.txt.\n",
      "2024-04-11 14:03:06,328 [MainThread  ] [INFO ]  Processing model.A.001.txt.\n",
      "2024-04-11 14:03:06,328 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpzhg8lk99/system.\n",
      "2024-04-11 14:03:06,329 [MainThread  ] [INFO ]  Processing files in ./metrics/sample/.\n",
      "2024-04-11 14:03:06,329 [MainThread  ] [INFO ]  Processing system.001.txt.\n",
      "2024-04-11 14:03:06,330 [MainThread  ] [INFO ]  Processing model.B.001.txt.\n",
      "2024-04-11 14:03:06,331 [MainThread  ] [INFO ]  Processing model.C.001.txt.\n",
      "2024-04-11 14:03:06,332 [MainThread  ] [INFO ]  Processing model.A.001.txt.\n",
      "2024-04-11 14:03:06,332 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpzhg8lk99/model.\n",
      "2024-04-11 14:03:06,333 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpyvh4gcw1/rouge_conf.xml\n",
      "2024-04-11 14:03:06,334 [MainThread  ] [INFO ]  Running ROUGE with command /home/ubuntu/apps/SummarizationEval/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/ubuntu/apps/SummarizationEval/pyrouge/tools/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpyvh4gcw1/rouge_conf.xml\n",
      "2024-04-11 14:03:06,430 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2024-04-11 14:03:06,432 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpg5swnnat/system and model files to /tmp/tmpg5swnnat/model.\n",
      "2024-04-11 14:03:06,433 [MainThread  ] [INFO ]  Processing files in ./metrics/sample/.\n",
      "2024-04-11 14:03:06,434 [MainThread  ] [INFO ]  Processing system.001.txt.\n",
      "2024-04-11 14:03:06,436 [MainThread  ] [INFO ]  Processing model.B.001.txt.\n",
      "2024-04-11 14:03:06,437 [MainThread  ] [INFO ]  Processing model.C.001.txt.\n",
      "2024-04-11 14:03:06,438 [MainThread  ] [INFO ]  Processing model.A.001.txt.\n",
      "2024-04-11 14:03:06,439 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpg5swnnat/system.\n",
      "2024-04-11 14:03:06,440 [MainThread  ] [INFO ]  Processing files in ./metrics/sample/.\n",
      "2024-04-11 14:03:06,440 [MainThread  ] [INFO ]  Processing system.001.txt.\n",
      "2024-04-11 14:03:06,441 [MainThread  ] [INFO ]  Processing model.B.001.txt.\n",
      "2024-04-11 14:03:06,442 [MainThread  ] [INFO ]  Processing model.C.001.txt.\n",
      "2024-04-11 14:03:06,442 [MainThread  ] [INFO ]  Processing model.A.001.txt.\n",
      "2024-04-11 14:03:06,443 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpg5swnnat/model.\n",
      "2024-04-11 14:03:06,444 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpwobovu09/rouge_conf.xml\n",
      "2024-04-11 14:03:06,444 [MainThread  ] [INFO ]  Running ROUGE with command /home/ubuntu/apps/SummarizationEval/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/ubuntu/apps/SummarizationEval/pyrouge/tools/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpwobovu09/rouge_conf.xml\n",
      "2024-04-11 14:03:06,543 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2024-04-11 14:03:06,546 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpecrfihf2/system and model files to /tmp/tmpecrfihf2/model.\n",
      "2024-04-11 14:03:06,547 [MainThread  ] [INFO ]  Processing files in ./metrics/sample/.\n",
      "2024-04-11 14:03:06,548 [MainThread  ] [INFO ]  Processing system.001.txt.\n",
      "2024-04-11 14:03:06,549 [MainThread  ] [INFO ]  Processing model.B.001.txt.\n",
      "2024-04-11 14:03:06,551 [MainThread  ] [INFO ]  Processing model.C.001.txt.\n",
      "2024-04-11 14:03:06,552 [MainThread  ] [INFO ]  Processing model.A.001.txt.\n",
      "2024-04-11 14:03:06,553 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpecrfihf2/system.\n",
      "2024-04-11 14:03:06,553 [MainThread  ] [INFO ]  Processing files in ./metrics/sample/.\n",
      "2024-04-11 14:03:06,554 [MainThread  ] [INFO ]  Processing system.001.txt.\n",
      "2024-04-11 14:03:06,554 [MainThread  ] [INFO ]  Processing model.B.001.txt.\n",
      "2024-04-11 14:03:06,555 [MainThread  ] [INFO ]  Processing model.C.001.txt.\n",
      "2024-04-11 14:03:06,556 [MainThread  ] [INFO ]  Processing model.A.001.txt.\n",
      "2024-04-11 14:03:06,556 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpecrfihf2/model.\n",
      "2024-04-11 14:03:06,557 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpnhne7f_p/rouge_conf.xml\n",
      "2024-04-11 14:03:06,558 [MainThread  ] [INFO ]  Running ROUGE with command /home/ubuntu/apps/SummarizationEval/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/ubuntu/apps/SummarizationEval/pyrouge/tools/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpnhne7f_p/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge-L(F) A: 0.28125\n",
      "Rouge-L(F) B: 0.44444\n",
      "Rouge-L(F) C: 0.29091\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rouge-L(F) A: {get_rouge_l_f('A')}\")\n",
    "print(f\"Rouge-L(F) B: {get_rouge_l_f('B')}\")\n",
    "print(f\"Rouge-L(F) C: {get_rouge_l_f('C')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a clear limitation of lexical overlap metrics, such as ROUGE: summary C, which was not very coherent ranks higher than summary A, which was fully coherent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try now an example of a semantic overlap metric, [BERTScore](https://github.com/Tiiiger/bert_score), an automatic evaluation metric from Zhang et. al (2020):\n",
    "> BERTScore leverages the pre-trained contextual embeddings from BERT and matches words in candidate and reference sentences by cosine similarity. It has been shown to correlate with human judgment on sentence-level and system-level evaluation.\n",
    "\n",
    "We are dealing with relatively long texts but BERT and related models can\"t process them. As per the BERTScore authors:\n",
    "> Because BERT, RoBERTa, and XLM with learned positional embeddings are pre-trained on sentences with max length 512, BERTScore is undefined between sentences longer than 510 (512 after adding [CLS] and [SEP] tokens). The sentences longer than this will be truncated. Please consider using XLNet which can support much longer inputs.\n",
    "\n",
    "Here is a description of the XLNet model from the [Hugging Face model card](https://huggingface.co/xlnet/xlnet-large-cased) (**emphasis** mine):\n",
    "> XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, **exhibiting excellent performance for language tasks involving long context**. Overall, XLNet achieves state-of-the-art (SOTA) results on various downstream language tasks including question answering, natural language inference, sentiment analysis, and document ranking.\n",
    "\n",
    "Next, we will instantiate a `BERTScorer` object, based on the XLNet model. The embedding layer is chosen as per [the authors recommendation](https://docs.google.com/spreadsheets/d/1RKOVpselB98Nnh_EOC4A2BYn8_201tmPODpNWu4w7xI/edit#gid=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import BERTScorer\n",
    "\n",
    "scorer = BERTScorer(\n",
    "    lang=\"en\",\n",
    "    model_type=\"xlnet/xlnet-large-cased\",\n",
    "    num_layers=7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\"s start by getting an intuition about the metric. We create some sample summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, F1 = scorer.score(summaries, [reference_text] * len(summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4748, 0.5723, 0.3627])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a comprehensive study of summarization evaluation, please check [the paper from Fabbri et al](https://arxiv.org/abs/2007.12626)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate some sample summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try now BERTScore with a couple of our summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_mixtral = pd.read_csv(\"./summaries/awesome_nature_100_mixtral_8x7b_instruct_summaries.csv\")\n",
    "df_llama2 = pd.read_csv(\"./summaries/awesome_nature_100_llama2_70b_chat_summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_00 = df_mixtral[\"transcript\"][0]\n",
    "summ_mixtral_00 = df_mixtral[\"MIXTRAL_8X7B_INSTRUCT_summary\"][0]\n",
    "summ_llama2_00 = df_llama2[\"LLAMA2_70B_CHAT_summary\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meet Odontochelys semitestacea. This little creature spends its days \n",
      "splashing in Late Triassic swamps with a host of other reptiles. Under the surface lies its best \n",
      "defense against attack: a hard shell on its belly. Odontochelys is an early ancestor \n",
      "of the turtle. Its half-shelled body illustrates an \n",
      "important point about the modern turtle: it actually has two shells that develop \n",
      "totally separately while the turtle is still an embryo. Both are extensions of the animal’s \n",
      "skeleton, and together they are made \n",
      "of almost 60 bones. Like other embryos, turtle embryos are made of \n",
      "undifferentiated cells that become specific cell types, and then organs and tissues, through gene activity and communication\n",
      "between cells. At first, turtle embryos look very similar\n",
      "to those of other reptiles, birds, and mammals, except for a bulge of cells called \n",
      "the carapacial ridge. The ridge expands around the body \n",
      "between the neck and lower back, creating a disc shape. It guides the formation of the upper part\n",
      "of the turtle’s shell, called the carapace, likely by attracting \n",
      "the cells that will become ribs. Instead of curving downwards \n",
      "to make a regular rib cage, the ribs move outwards towards the \n",
      "carapacial ridge. They then secrete a signaling protein that converts surrounding cells \n",
      "into bone-forming cells. These fifty bones grow until they meet \n",
      "and connect with sutures. A ring of bone solidifies \n",
      "the carapace’s edges. The outer layer of skin cells produces \n",
      "the scales, known as scutes, that cover the carapace. The development of the bottom half \n",
      "of the shell, the plastron, is driven by neural crest cells, which can produce a variety of different \n",
      "cell types including neurons, cartilage and bone. A thick shield of these cells \n",
      "spreads across the belly, coming together in regions that produce\n",
      "nine plate-like bones. Eventually, these connect to the \n",
      "carapace by sutures. A turtle’s shell has obvious advantages\n",
      "for guarding against predators, but the rigid casing also presents \n",
      "some challenges. As the turtle grows, the sutures between the bones \n",
      "of the carapace and plastron spread. Most mammals and reptiles rely on a\n",
      "flexible rib cage that expands to allow them to breathe, but turtles use abdominal muscles \n",
      "attached to the shell instead: one to breathe in, \n",
      "and one to breathe out. So how did the shell evolve? Though there are still gaps in the \n",
      "fossil record, the first step seems to have been \n",
      "a thickening of the ribs. The oldest known turtle ancestor, a creature called Eunotosaurus africanus, lived 260 million years ago and looked \n",
      "almost nothing like a modern turtle, but it had a set of broad, flat ribs that anchored the muscles \n",
      "of its powerful forearms. Eunotosaurus was likely \n",
      "a burrowing creature, digging homes for itself in what’s \n",
      "now southern Africa. Odontochelys semitestacea illustrates \n",
      "another, later step in turtle evolution, with thick ribs like Eunotosaurus \n",
      "plus a belly plate for protection. Our first fossil evidence of the full \n",
      "shell characteristic of modern turtles is about 210 million years old, and belongs to a species called \n",
      "Proganochelys quenstedti, whose ribs had fused. Proganochelys could move \n",
      "between water and land. Unlike modern turtles, it couldn’t retract\n",
      "its head into its shell, but had defensive spines on its neck. Modern turtle shells are almost as diverse\n",
      "as the turtles themselves. Sea turtles have flatter, lighter shells \n",
      "for streamlined gliding through the water. Land-dwelling tortoises, meanwhile, have domed shells that can slip free of\n",
      "predators’ jaws and help them turn right-side up if \n",
      "they fall on their backs. Leatherback and softshell turtles have shells without the ring of bone \n",
      "around the edge of the carapace or the tough scutes covering it, making it easier for them to \n",
      "squeeze into tight spaces.\n"
     ]
    }
   ],
   "source": [
    "print(reference_00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video explains how turtle shells evolved twice. The first turtle ancestor, Eunotosaurus africanus, had broad, flat ribs that anchored the muscles of its powerful forearms. The second turtle ancestor, Odontochelys semitestacea, had thick ribs and a belly plate for protection. The first fossil evidence of the full shell characteristic of modern turtles is about 210 million years old, and belongs to a species called Proganochelys quenstedti, whose ribs had fused. Modern turtle shells are diverse, with sea turtles having flatter, lighter shells for streamlined gliding through the water, land-dwelling tortoises having domed shells that can slip free of predators’ jaws, and leatherback and softshell turtles having shells without the ring of bone around the edge or the tough scutes covering it.\n",
      "\n",
      "Curious facts:\n",
      "\n",
      "* Turtles have two shells that develop separately while the turtle is still an embryo.\n",
      "* The upper part of the turtle’s shell, called the carapace, is made of fifty bones that grow until they meet and connect with sutures.\n",
      "* The bottom half of the shell, the plastron, is driven by neural crest cells, which can produce a variety of different cell types including neurons, cartilage and bone.\n",
      "* The oldest known turtle ancestor, Eunotosaurus africanus, lived 260 million years ago and looked almost nothing like a modern turtle.\n",
      "* The first fossil evidence of the full shell characteristic of modern turtles is about 210 million years old, and belongs to a species called Proganochelys quenstedti, whose ribs had fused.\n",
      "* Modern turtle shells are almost as diverse as the turtles themselves, with sea turtles having flatter, lighter shells for streamlined gliding through the water, land-dwelling tortoises having domed shells that can slip free of predators’ jaws, and leatherback and softshell turtles having shells without the ring of bone around the edge or the tough scutes covering it.\n"
     ]
    }
   ],
   "source": [
    "print(summ_mixtral_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video discusses the evolution of turtle shells, which have two separate shells that develop independently while the turtle is still an embryo. The upper shell, or carapace, is made of 50 bones that form from a bulge of cells called the carapacial ridge. The lower shell, or plastron, is made of nine plate-like bones that are produced by neural crest cells. The shell provides protection for turtles, but also presents challenges for breathing. The video also mentions that the first known turtle ancestor, Eunotosaurus africanus, had broad, flat ribs that anchored the muscles of its powerful forearms.\n",
      "\n",
      "Curious facts:\n",
      "\n",
      "* Turtles have two separate shells that develop independently while they are still embryos.\n",
      "* The upper shell, or carapace, is made of 50 bones that form from a bulge of cells called the carapacial ridge.\n",
      "* The lower shell, or plastron, is made of nine plate-like bones that are produced by neural crest cells.\n",
      "* The shell provides protection for turtles, but also presents challenges for breathing.\n",
      "* The first known turtle ancestor, Eunotosaurus africanus, had broad, flat ribs that anchored the muscles of its powerful forearms.\n",
      "* Modern turtle shells are almost as diverse as the turtles themselves, with different shapes and features for different species.\n"
     ]
    }
   ],
   "source": [
    "print(summ_llama2_00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the word lenghts of each piece:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of reference trasncript (words): 609\n",
      "Length of Mixtral summary (words): 303\n",
      "Length of Llama2 summary (words): 208\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of reference trasncript (words): {len(reference_00.split())}\")\n",
    "print(f\"Length of Mixtral summary (words): {len(summ_mixtral_00.split())}\")\n",
    "print(f\"Length of Llama2 summary (words): {len(summ_llama2_00.split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw a couple of observations:\n",
    "* Models produced summaries from roughly 1/2 to 1/3 of the original length\n",
    "* None of the models was very good at following the instruction to keep the summary in 100 words or less. This is becuase language models in general are not very good at doing math, especially meta-math, or math about the actual generation.\n",
    "\n",
    "Let's calculate now the BERTScore for these summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7944, 0.6852])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, F1 = scorer.score([summ_mixtral_00, summ_llama2_00], [reference_00] * 2)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a sanity check to verify if BERTScore with XLNet is actually sensitive to the whole texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_00 += \"\"\"this a dummy sentence with some extra-domain terms meant to\n",
    "lower the score of the summaries: computer, GPU, processor, algorithm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7854, 0.6781])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, F1 = scorer.score([summ_mixtral_00, summ_llama2_00], [reference_00] * 2)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the scores were lowered slightly, so this proves that took into account the whole reference text, thanks to XLNet longer context over BERT and variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating a winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_winner(scorer, row):\n",
    "    summary_mixtral = row[\"MIXTRAL_8X7B_INSTRUCT_summary\"]\n",
    "    summary_llama2 = row[\"LLAMA2_70B_CHAT_summary\"]\n",
    "    reference = row[\"transcript\"]\n",
    "    _, _, F1 = scorer.score(\n",
    "        [summary_mixtral, summary_llama2],\n",
    "        [reference] * 2\n",
    "    )\n",
    "    if F1[0] > F1[1]:\n",
    "        return \"mixtral\"\n",
    "    else:\n",
    "        return \"llama2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_mixtral.assign(LLAMA2_70B_CHAT_summary=df_llama2[\"LLAMA2_70B_CHAT_summary\"])\n",
    "df_all[\"winner\"] = df_all.apply(lambda x: calculate_winner(scorer, x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidentally, let's calculate acceleration of evaluation of GPU vs CPU (the BERTScorer is allocated by default on the GPU, when available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_cpu = BERTScorer(\n",
    "    lang=\"en\",\n",
    "    model_type=\"xlnet/xlnet-large-cased\",\n",
    "    num_layers=7,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df_all[:10].apply(lambda x: calculate_winner(scorer_cpu, x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten summaries on the CPU take ~25 seconds, which would mean ~250 seconds for the 100 summaries against ~10 seconds with the GPU, so we are achieving a ~25x speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mixtral_won = df_all.loc[df_all[\"winner\"] == \"mixtral\"].shape[0]\n",
    "llama2_won = df_all.loc[df_all[\"winner\"] == \"llama2\"].shape[0]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_index = [0]\n",
    "index_mixtral = [-0.1]\n",
    "index_llama2 = [+0.1]\n",
    "labels = [\"Mixtral-8x7B-Instruct\", \"Llama2-70B-chat\"]\n",
    "plt.bar(index_mixtral, mixtral_won, label='Mixtral-8x7B-instruct', width=0.2)\n",
    "plt.bar(index_llama2, llama2_won, label='Llama2-70b-chat', width=0.2)\n",
    "plt.xticks(plot_index, labels=[\"\"])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Wins')\n",
    "plt.title('Win rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixtral won in this experiment of summarizing YouTube transcripts with Llama2 close in the win rate. \n",
    "\n",
    "To wrap up, let's save the results to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(f\"./summaries/awesome_nature_100_winner_summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
