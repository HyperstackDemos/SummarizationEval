# Summarization with LLMs: inference performance and evaluation insights

In this repo, we walk you through an experiment for a common use case of Large Language Models (LLMs): text summarization.

We compare two strong open source models: Mixtral 8x7B and LLama2 70B.

We consider two comparison axis:
* inference performance, when run on NVIDIA GPUs for hardware acceleration, and
* task performance, evaluating the generated summaries with a suitable NLP evaluation metric.

You can follow the notebooks in order for a walk-through of the experiments.

## Video tutorials (3 parts)

Follow along with the video tutorials in 3 parts.

**Part 1**

[![Watch the video](https://img.youtube.com/vi/61KZtaKCC00/hqdefault.jpg)](https://www.youtube.com/embed/61KZtaKCC00)

**Part 2**

[![Watch the video](https://img.youtube.com/vi/YnfgLO0TN1g/hqdefault.jpg)](https://www.youtube.com/embed/YnfgLO0TN1g)


**Part 3**

[![Watch the video](https://img.youtube.com/vi/rDzDW033AY0/hqdefault.jpg)](https://www.youtube.com/embed/rDzDW033AY0)

